INFRASTRUCTURE:
resources used to run our application on cloud.
ex: ec2, s3, elb, vpc --------------


in genral we used to deploy infra on manual 

Manual:
1. time consume
2. manual work
3. commiting mistakes

Automate -- > Terraform -- > code -- > hcl (Hashicorp configuration languge)



its a tool used to make infrastructure automation.
its a free and opensource.
its platform independent.
it comes on year 2014.
who: mitchel hasimoto 
ownde: hasicorp 
terraform is written on go language.
We can call terraform as IAAC TOOL.

HOW IT WORKS:
terraform uses code to automate the infra.
we use HCL : HashiCorp Configuration Language.

IAAC: Infrastructure as a code.

Code --- > execute --- > Infra 

ADVANTGAES:
1. Reuseable 
2. Time saving
3. Automation
4. Avoiding mistakes
5. Dry run


CFT = AWS
ARM = AZURE
GDE = GOOGLE

TERRAFROM = ALL CLOUDS

INSTALLING TERRAFORM:

sudo yum install -y yum-utils shadow-utils
sudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/AmazonLinux/hashicorp.repo
sudo yum -y install terraform
aws configure


mkdir terraform
cd terraform

vim main.tf 

provider "aws" {
region = "us-east-1"
}

resource "aws_instance" "one" {
ami = "ami-03eb6185d756497f8"
instance_type = "t2.micro"
}


TERRAFORM COMMANDS:
terraform init	: initalize the provider plugins on backend
terraform plan	: to create execution plan
terrafrom apply : to create resources
terrafrom destroy : to delete resources

provider "aws" {
region = "ap-south-1"
}

resource "aws_instance" "one" {
count = 5
ami = "ami-0b41f7055516b991a"
instance_type = "t2.micro"
}

terraform apply --auto-approve
terraform destroy --auto-approve


STATE FILE: used to store the resource information which is created by terraform
to track the resource activities
in real time entire resource info is on state file.
we need to keep it safe
if we lost this file we cant track the infra.
Command:
terraform state list

terrafrom target: used to destroy the specific resource 
terraform state list
single target: terraform destroy -target="aws_instance.one[3]"
multi targets: terraform destroy -target="aws_instance.one[1]" -target="aws_instance.one[2]"


TERRAFORM VARIABLES:
provider "aws" {
region = "ap-south-1"
}

resource "aws_instance" "one" {
count = var.instance_count
ami = "ami-0b41f7055516b991a"
instance_type = var.instance_type
}

variable "instance_type" {
description = "*"
type = string
default = "t2.micro"
}

variable "instance_count" {
description = "*"
type = number
default = 5
}

terraform apply --auto-approve
terraform destroy --auto-approve

VARIABLES, OUTPUTS AND IMPORT

TERRAFORM VAR FILES:
these files used to store variables seperately on terraform.



cat main.tf
provider "aws" {
region = "us-east-1"
}

resource "aws_instance" "one" {
count = var.instance_count
ami = "ami-03eb6185d756497f8"
instance_type = var.instance_type
tags = {
Name = "raham-server"
}
}

cat variable.tf
variable "instance_count" {
description = "*"
type = number
default = 3
}

variable "instance_type" {
description = "*"
type = string
default = "t2.micro"
}

terraform apply --auto-approve 
terraform destroy --auto-approve


cat main.tf
provider "aws" {
region = "ap-south-1"
}

resource "aws_instance" "one" {
count = var.instance_count
ami = "ami-0b41f7055516b991a"
instance_type = var.instance_type
tags = {
Name = "raham-server"
}
}

cat variable.tf
variable "instance_count" {
}

variable "instance_type" {
}

cat dev.tfvars
instance_count = 1

instance_type = "t2.micro"

cat test.tfvars
instance_count = 2

instance_type = "t2.medium"

terraform apply --auto-approve -var-file="dev.tfvars"
terraform destroy --auto-approve -var-file="dev.tfvars"


terraform apply --auto-approve -var-file="test.tfvars"
terraform destroy --auto-approve -var-file="test.tfvars"


TERRAFORM CLI:
we can pass inputs for terraform from cli.

provider "aws" {
region = "ap-south-1"
}

resource "aws_instance" "one" {
ami = "ami-0b41f7055516b991a"
instance_type = var.instance_type
tags = {
Name = "raham-server"
}
}

variable "instance_type" {
}

terraform apply --auto-approve -var="instance_type=t2.medium"
terraform destroy --auto-approve -var="instance_type=t2.medium"

TERRAFORM OUTPUTS: used to print the resource properties.
ex: public-ip, dns, instance type

provider "aws" {
region = "ap-south-1"
}

resource "aws_instance" "one" {
ami = "ami-0b41f7055516b991a"
instance_type = "t2.medium"
tags = {
Name = "raham-server"
}
}

output "raham" {
value = [aws_instance.one.public_ip, aws_instance.one.private_ip, aws_instance.one.public_dns, aws_instance.one.private_dns]
}


TERRAFORM IMPORT: used to import and track the resources which is created manually.


cat main.tf
provider "aws" {
region = "ap-south-1"
}

resource "aws_instance" "one" {
}

terraform import aws_instance.one i-0f4c0d5d3bb6dc758

provider "aws" {
region = "us-east-1"
}

resource "aws_s3_bucket" "one" {
bucket = "rahamshaik9988tetrrbcuket"
}

resource "aws_ebs_volume" "two" {
size = 20
availability_zone = "us-east-1b"
tags = {
Name = "raham-ebs"
}
}

resource "aws_iam_user" "three" {
name = "rahams"
}

resource "aws_instance" "four" {
ami = "ami-03eb6185d756497f8"
instance_type = "t2.micro"
tags = {
Name = "Raham-terraserver"
}
}

Terraform taint: used to recreate specific objects 
in real time some resource we need to recrete if it will not work properly 
then we can use taint concetp

terraform taint aws_instance.four
terraform apply --auto-approve

Terraform Lifecycle:

Prevent_destroy: used to keep secure our resources without destroying.

provider "aws" {
region = "us-east-1"
}

resource "aws_s3_bucket" "one" {
bucket = "rahamshaik9988tetrrbcuket"
}

resource "aws_ebs_volume" "two" {
size = 20
availability_zone = "us-east-1b"
tags = {
Name = "raham-ebs"
}
}

resource "aws_iam_user" "three" {
name = "rahams"
}

resource "aws_instance" "four" {
ami = "ami-03eb6185d756497f8"
instance_type = "t2.micro"
tags = {
Name = "Raham-terraserver"
}
lifecycle {
prevent_destroy = true
}

TERRAFORM FMT: used to provide the indentation for terraform.

VERSION CONSTARINT: used to change the provider version.

provider "aws" {
  region = "us-east-1"
}

terraform {
  required_providers {
    aws = {
      source = "hashicorp/aws"
      version = ">5.19.0"
    }
  }
}

terraform init -upgrade

Local resources:

provider "aws" {
  region = "us-east-1"
}

resource "local_file" "one" {
filename = "abc.txt"
content= "Hai all this file is created by terraform"
}


provider "aws" {
  region = "us-east-1"
}

terraform {
  required_providers {
    local = {
      source = "hashicorp/local"
      version = "2.2.0"
    }
  }
}

TERRAFORM LOCALS:
its a block used to define the values.
we can define the vaule once and used it for multiple times.

provider "aws" {
region = "ap-south-1"
}

locals {
env = "test"
}

resource "aws_vpc" "one" {
cidr_block = "10.0.0.0/16"
tags = {
Name = "${local.env}-vpc"
}
}

resource "aws_subnet" "two" {
cidr_block = "10.0.0.0/16"
availability_zone = "ap-south-1a"
vpc_id = aws_vpc.one.id
tags = {
Name = "${local.env}-subnet"
}
}

resource "aws_instance" "three" {
subnet_id = aws_subnet.two.id
ami = "ami-06006e8b065b5bd46"
instance_type = "t2.micro"
tags = {
Name = "${local.env}-server"
}
}

TERRAFORM WORKSPACE:
WORKSPACE: Where we write the code and execute operations.
it is used to isolate the env.
in real time all the works we do on workspaces only.
if we perform an operation on one workspace it wont affect another workspace.


NOTE:
1. we can't delete our current workspace.
2. we can't delete our workspace without deleting resources.
3. we cant't delete default workspace.

COMMANDS:

terraform workspace list	: to list workspaces
terraform workspace new dev	: to create a new workspace	
terraform workspace show	: to show current workspace
terraform workspace select prod	: to switch the workspaces
terraform workspace delete prod	: to delete the workspaces


provider "aws" {
region = "ap-south-1"
}

locals {
env = "${terraform.workspace}"
}

resource "aws_vpc" "one" {
cidr_block = "10.0.0.0/16"
tags = {
Name = "${local.env}-vpc"
}
}

resource "aws_subnet" "two" {
cidr_block = "10.0.0.0/16"
availability_zone = "ap-south-1a"
vpc_id = aws_vpc.one.id
tags = {
Name = "${local.env}-subnet"
}
}

resource "aws_instance" "three" {
subnet_id = aws_subnet.two.id
ami = "ami-06006e8b065b5bd46"
instance_type = "t2.micro"
tags = {
Name = "${local.env}-server"
}
}


TERRAFORM GRAPH: used to show the flow chart of our infra
terraform graph
copy paste the content in graphviz online


ALIAS AND PROVIDER: used to create resources on mutliple regions in single file.

provider "aws" {
region = "ap-south-1"
}

resource "aws_instance" "three" {
ami = "ami-06006e8b065b5bd46"
instance_type = "t2.large"
tags = {
Name = "mumbai-server"
}
}

provider "aws" {
region = "ap-northeast-1"
alias = "tokyo"
}

resource "aws_instance" "four" {
provider = aws.tokyo
ami = "ami-0bcf3ca5a6483feba"
instance_type = "t2.large"
tags = {
Name = "tokyo-server"
}
}


provider "aws" {
region = "ap-south-1"
}

resource "aws_instance" "one" {
ami = "ami-06006e8b065b5bd46"
instance_type = "t2.micro"
tags = {
Name = "raham"
}
lifecycle {
prevent_destroy = true
}
}


provider "aws" {
region = "ap-south-1"
}

resource "aws_instance" "one" {
ami = "ami-06006e8b065b5bd46"
instance_type = "t2.micro"
tags = {
Name = "raham"
}
lifecycle {
prevent_destroy = false
}
}

Prevent Destroy: it will not delete the resources
Ignore changes: it will not replicate the changes we have done to server
Depends on: it will depend on another resource to create.

tERRAFORM REMOTE BACKEND SETUP:
when we create infra the information of resources will store on state file.
so it will be tracking the infra information.
so we need to take backup of that file.
if we lost that file we cant track the infra.
so we prefer to locate the state file on remote loaction.
here im using s3 as remote backend.


provider "aws" {
region = "ap-south-1"
}

terraform {
  backend "s3" {
    bucket = "rahamshaikterraprodbcuket0088"
    key    = "prod/terraform.tfstate"
    region = "ap-south-1"
  }
}

resource "aws_instance" "one" {
ami = "ami-06006e8b065b5bd46"
instance_type = "t2.micro"
tags = {
Name = "raham"
}
}

create Bucket manually

Note: while using new block always we need to run terraform init
otherwise, plugins will not be downloaded

after removing backend setup run this command:
terraform init -migrate-state


TERRAFORM REFRESH: used to refresh and replicate the changes to state file.
it will compare terraform state file with resource.
if it is exsits it will show, otherwise it will not show.

LOCAL RESOURCES:


provider "aws" {
region = "ap-south-1"
}

resource "local_file" "one" {
filename = "abc.txt"
content = "hai all this file is creatd from terraform"
}

VERSION CONSTRAINTS:
it is used to change the provider version plugins.
can be applicable for all providers.


provider "aws" {
region = "ap-south-1"
}

terraform {
  required_providers {
    aws = {
      source = "hashicorp/aws"
      version = "<5.22.0"
    }
  }
}


provider "aws" {
region = "ap-south-1"
}

terraform {
  required_providers {
    local = {
      source = "hashicorp/local"
      version = "<2.2.0"
    }
  }
}



DYNAMIC BLOCK: it is used to reduce the length of code and used for reusabilty of code in loop.

provider "aws" {
}

locals {
  ingress_rules = [{
    port        = 443
    description = "Ingress rules for port 443"
    },
    {
      port        = 80
      description = "Ingree rules for port 80"
  },
  {
      port        = 8080
      description = "Ingree rules for port 8080"

  }]
}

resource "aws_instance" "ec2_example" {
  ami                    = "ami-0c02fb55956c7d316"
  instance_type          = "t2.micro"
  vpc_security_group_ids = [aws_security_group.main.id]
  tags = {
    Name = "Terraform EC2"
  }
}

resource "aws_security_group" "main" {

  egress = [
    {
      cidr_blocks      = ["0.0.0.0/0"]
      description      = "*"
      from_port        = 0
      ipv6_cidr_blocks = []
      prefix_list_ids  = []
      protocol         = "-1"
      security_groups  = []
      self             = false
      to_port          = 0
  }]

  dynamic "ingress" {
    for_each = local.ingress_rules

    content {
      description = "*"
      from_port   = ingress.value.port
      to_port     = ingress.value.port
      protocol    = "tcp"
      cidr_blocks = ["0.0.0.0/0"]
    }
  }

  tags = {
    Name = "terra sg"
  }
}



provider "aws" {
region = "ap-south-1"
}

resource "aws_instance" "one" {
count = length(var.instance_type)
ami = "ami-06006e8b065b5bd46"
instance_type = var.instance_type[count.index]
tags = {
Name = var.instance_name[count.index]
}
}

variable "instance_type" {
default = ["t2.medium", "t2.micro", "t2.nano"]
}

variable "instance_name" {
default = ["webserver", "appserver", "dbserver"]
}


FOR_EACH:

provider "aws" {
}

resource "aws_instance" "two" {
for_each = toset(["web-server", "app-server", "db-server"])
ami = "ami-04beabd6a4fb6ab6f"
instance_type = "t2.micro"
tags = {
Name = "${each.key}"
}
} 



1. Explain the difference between Terraform and other Infrastructure as Code (IaC) tools like Ansible, Puppet, and Chef.


Terraform is used to create and manage cloud infrastructure (like servers and networks) and replaces resources if changes are needed to     keep everything consistent.

Ansible, Puppet, and Chef are used to configure and manage servers (like installing software or setting permissions) and typically update systems directly without replacing them.

In short: Terraform is for setting up infrastructure; the others are for configuring and maintaining it.

1a. What is Provisioning?
Provisioning is the process of setting up and preparing resources so that they are ready to be used. Think of it as getting everything in place before you can start using something.


1b. Definition

Mutable Infrastructure: This refers to systems that can be modified after they have been deployed. You can change configurations, apply updates, or install new software directly on existing servers without needing to replace them.

Terraform is a powerful tool that enables the implementation of immutable infrastructure, a model where resources are not modified after deployment. Instead, any changes or updates require the creation of new resources. Here’s how this works in detail:

Immutable Infrastructure: This is a model where once a server or resource is deployed, it cannot be changed or modified. If an update or change is needed, a new instance is created, and the old one is decommissioned.

Declarative Tool: Terraform Meaning
Terraform is a declarative tool used for managing infrastructure as code (IaC). Being declarative means that users specify what they want their infrastructure to look like, rather than detailing how to achieve that outcome


How It Works
State Management: Terraform maintains a state file that records the current state of your infrastructure. This allows it to track what resources exist and what changes need to be made when configurations are updated. For instance, if you change the number of virtual machines from five to ten in your configuration, Terraform recognizes that it needs to create five additional instances.
Execution Plan: Before applying changes, Terraform generates an execution plan that outlines what actions will be taken based on your configuration. This helps users understand the impact of their changes before they are applied.


2. How do you manage state in Terraform, and what are some best practices for state management?

  
3. Describe the purpose of Terraform modules and how you would use them in a project.




4. How do you handle secrets and sensitive data in Terraform configurations?

5. Explain the Terraform workflow, including the roles of terraform init, terraform plan, terraform apply, and terraform destroy.
6. What are Terraform providers, and how do you configure them?
7. Describe how to use the terraform import command.
8. How do you manage multiple environments (e.g., development, staging, production) in Terraform?
9. What are Terraform workspaces, and how do they help in managing infrastructure?
10. Explain how you can use Terraform to manage dependencies between resources.
11. How do you perform resource tainting and why is it useful?
12. Describe the process of upgrading a Terraform provider.
13. How do you handle Terraform drift detection and remediation?
14. What are some strategies for ensuring high availability and disaster recovery with Terraform?
15. Explain the use of terraform fmt and terraform validate in maintaining code quality.
16. How do you manage infrastructure versioning and collaboration in Terraform?
17. Describe a scenario where you encountered a complex Terraform issue and how you resolved it.
18. Explain the difference between terraform apply and terraform apply -auto-approve.
19. How do you integrate Terraform with CI/CD pipelines?
20. What are some common Terraform gotchas and how do you avoid them?
21. How do you use Terraform with multi-cloud deployments?
22. Describe how you would handle a situation where a Terraform apply failed in the middle of execution.
23. How do you manage provider version constraints in Terraform configurations?
24. Explain the purpose and use of terraform graph.
25. How do you configure remote backends in Terraform, and why are they useful?
26. Describe how to use the Terraform Registry.
27. How do you handle conditional logic in Terraform?
28. What are some best practices for writing reusable and maintainable Terraform code?
29. Explain the purpose and usage of data sources in Terraform.
30. How do you handle breaking changes introduced in new Terraform versions?
